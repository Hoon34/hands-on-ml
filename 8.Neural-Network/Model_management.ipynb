{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Model Mangement #\n",
    "\n",
    "It is easy to store trained keras model if we use sequential or functional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings ; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use california data for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8789 - val_loss: 0.5370\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.5002 - val_loss: 0.4818\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.4675 - val_loss: 0.4708\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.4642 - val_loss: 0.4705\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.4456 - val_loss: 0.4525\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 739us/step - loss: 0.4373 - val_loss: 0.4766\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.4280 - val_loss: 0.4479\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.4219 - val_loss: 0.4399\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.4156 - val_loss: 0.4312\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.4207 - val_loss: 0.4307\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 733us/step - loss: 0.4059 - val_loss: 0.4230\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 750us/step - loss: 0.4044 - val_loss: 0.4212\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 800us/step - loss: 0.3972 - val_loss: 0.4153\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.3947 - val_loss: 0.4145\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.3968 - val_loss: 0.4140\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3896 - val_loss: 0.4214\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.4053 - val_loss: 0.4054\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3844 - val_loss: 0.4076\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.3816 - val_loss: 0.4238\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.3807 - val_loss: 0.3974\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3791 - val_loss: 0.3979\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3722 - val_loss: 0.4035\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 781us/step - loss: 0.3712 - val_loss: 0.3965\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.3700 - val_loss: 0.3861\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.3694 - val_loss: 0.3886\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3649 - val_loss: 0.3965\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3620 - val_loss: 0.3905\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 764us/step - loss: 0.3599 - val_loss: 0.3832\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.3591 - val_loss: 0.3787\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3556 - val_loss: 0.3764\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras_model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can save a model by one code line. We are also able to load model and make predictions like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"keras_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #\n",
    "However, generaly train step continues for a few hours. In this case, we have to save some checkpoints during the train step not to loss all from computer error. So we use **callback**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 750us/step - loss: 0.3531\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 572us/step - loss: 0.3523\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.3650\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 578us/step - loss: 0.3499\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 605us/step - loss: 0.3513\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 657us/step - loss: 0.3498\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 621us/step - loss: 0.3556\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.3906\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.3624\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.3538\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"keras_model1.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use validation set during train step, we can set **save_best_only=True** when we make model checkpoint. Then it saves model only at the best validation set score. We don't need to worry about overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3617\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3427 - val_loss: 0.3656\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.3505 - val_loss: 0.3594\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.3427 - val_loss: 0.3551\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 789us/step - loss: 0.3399 - val_loss: 0.3557\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.3353 - val_loss: 0.3564\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.3410- ETA: 0s - loss: 0. - 0s 825us/step - loss: 0.3387 - val_loss: 0.3522\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3353 - val_loss: 0.3518\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3324 - val_loss: 0.3505\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 883us/step - loss: 0.3336 - val_loss: 0.3502\n"
     ]
    }
   ],
   "source": [
    "checkpoint1 = keras.callbacks.ModelCheckpoint(\"keras_model1.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can load the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"keras_model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method to realize earlystopping is to use **EarlyStopping** callback. It stops train if validation score doesn't imporve anymore. we can use both checkpoint save callback and earlystopping callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.3568\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.3305 - val_loss: 0.3492\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3292 - val_loss: 0.3479\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.3330 - val_loss: 0.3493\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.3287 - val_loss: 0.3531\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.3263 - val_loss: 0.4994\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.3336 - val_loss: 0.3531\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.3263 - val_loss: 0.3486\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3262 - val_loss: 0.3441\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3255 - val_loss: 0.3413\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3249 - val_loss: 0.3490\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 747us/step - loss: 0.3294 - val_loss: 0.3458\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.3253 - val_loss: 0.3403\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.3251 - val_loss: 0.4289\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3258 - val_loss: 0.3417\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 837us/step - loss: 0.3311 - val_loss: 0.3533\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.3222 - val_loss: 0.3407\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.3223 - val_loss: 0.3467\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3266 - val_loss: 0.3393\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3196 - val_loss: 0.3400\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3308 - val_loss: 0.3424\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3204 - val_loss: 0.3375\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3198 - val_loss: 0.3390\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.3245 - val_loss: 0.3566\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.3239 - val_loss: 0.3377\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.3246 - val_loss: 0.3414\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 742us/step - loss: 0.3190 - val_loss: 0.3393\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 747us/step - loss: 0.3223 - val_loss: 0.3401\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.3292 - val_loss: 0.3592\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.3286 - val_loss: 0.3420\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3146 - val_loss: 0.3383\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3187 - val_loss: 0.3366\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3473 - val_loss: 0.3588\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3259 - val_loss: 0.3444\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3257 - val_loss: 0.3481\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.3429 - val_loss: 0.3446\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3184 - val_loss: 0.3401\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.3165 - val_loss: 0.3376\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.3165 - val_loss: 0.3350\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3156 - val_loss: 0.3340\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3140 - val_loss: 0.3351\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3131 - val_loss: 0.3441\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3166 - val_loss: 0.3318\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.3147 - val_loss: 0.3400\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.3139 - val_loss: 0.3361\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.3157 - val_loss: 0.3907\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 808us/step - loss: 0.3149 - val_loss: 0.3315\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.3121 - val_loss: 0.3373\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.3111 - val_loss: 0.3285\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.3106 - val_loss: 0.3280\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3115 - val_loss: 0.3304\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3276\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3127 - val_loss: 0.3304\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.3111 - val_loss: 0.3354\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 843us/step - loss: 0.3232 - val_loss: 0.3349\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3106 - val_loss: 0.3400\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3098 - val_loss: 0.3284\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.3098 - val_loss: 0.3278\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.3083 - val_loss: 0.3312\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.3126 - val_loss: 0.3371\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3379\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 947us/step - loss: 0.3107 - val_loss: 0.3287\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint1, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beacuse train step is automatically stopped when the model doesn't imporve anymore, we can set number of epochs much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Hyperparameters ###\n",
    "\n",
    "Flexibility of neural network can be a disadvantage. we can control number of layers, number of neurons, activation funcion and weight initialization etc. Then how we know what combination of hyperparameters is best for given problem? One way is to try a lot of combination of hyperparameters and check what model has best score in validation set. We can search hyperparameter space using **GridSearchCV** and **RandomizedSearchCV**. To do this work, we have to change keras model to be seen like sklearn etimatior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function makes simple Sequential model for simple regression and compiles models for SGD SGD optimizer whcih uses designated learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KerasRegressor** object is a simple wrapper that covers keras made by keras_model. Since we didn't set any hyperparameter it will use basic hyperparameter. Now we can use it like sklearn regression estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 1.3910 - val_loss: 0.6606\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 666us/step - loss: 0.6276 - val_loss: 0.5873\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 689us/step - loss: 0.5704 - val_loss: 0.5505\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.5385 - val_loss: 0.5250\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 729us/step - loss: 0.5171 - val_loss: 0.5089\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.5061 - val_loss: 0.5194\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.5074 - val_loss: 0.4919\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 733us/step - loss: 0.4854 - val_loss: 0.5049\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.4787 - val_loss: 0.5116\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.4727 - val_loss: 0.4816\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.4707 - val_loss: 0.4776\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 702us/step - loss: 0.4667 - val_loss: 0.4773\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.4602 - val_loss: 0.4764\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 733us/step - loss: 0.4568 - val_loss: 0.4681\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 727us/step - loss: 0.4531 - val_loss: 0.4663\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.4511 - val_loss: 0.4632\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.4468 - val_loss: 0.4584\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 756us/step - loss: 0.4435 - val_loss: 0.4555\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 663us/step - loss: 0.4387 - val_loss: 0.4508\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.4358 - val_loss: 0.4485\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.4323 - val_loss: 0.4445\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.4294 - val_loss: 0.4426\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.4269 - val_loss: 0.4389\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.4255 - val_loss: 0.4390\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.4231 - val_loss: 0.4364\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.4205 - val_loss: 0.4373\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.4188 - val_loss: 0.4316\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 689us/step - loss: 0.4171 - val_loss: 0.4315\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 729us/step - loss: 0.4148 - val_loss: 0.4292\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 747us/step - loss: 0.4130 - val_loss: 0.4286\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 732us/step - loss: 0.4113 - val_loss: 0.4252\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.4109 - val_loss: 0.4270\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.4083 - val_loss: 0.4221\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.4075 - val_loss: 0.4221\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.4053 - val_loss: 0.4190\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.4043 - val_loss: 0.4187\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.4025 - val_loss: 0.4177\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.4015 - val_loss: 0.4166\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.4000 - val_loss: 0.4159\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.3983 - val_loss: 0.4151\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.3974 - val_loss: 0.4180\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3960 - val_loss: 0.4130\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 711us/step - loss: 0.3955 - val_loss: 0.4100\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.3931 - val_loss: 0.4074\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.3921 - val_loss: 0.4084\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 726us/step - loss: 0.3908 - val_loss: 0.4090\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.3897 - val_loss: 0.4057\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3885 - val_loss: 0.4052\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.3879 - val_loss: 0.4031\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3861 - val_loss: 0.4027\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.3849 - val_loss: 0.4011\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 803us/step - loss: 0.3839 - val_loss: 0.4035\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.3826 - val_loss: 0.3983\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 781us/step - loss: 0.3815 - val_loss: 0.3972\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3803 - val_loss: 0.3987\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 811us/step - loss: 0.3796 - val_loss: 0.3967\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.3795 - val_loss: 0.3947\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3773 - val_loss: 0.3946\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.3764 - val_loss: 0.3935\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 753us/step - loss: 0.3755 - val_loss: 0.3933\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3749 - val_loss: 0.3913\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.3738 - val_loss: 0.3908\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 767us/step - loss: 0.3733 - val_loss: 0.3888\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.3719 - val_loss: 0.3907\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3716 - val_loss: 0.3902\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 739us/step - loss: 0.3703 - val_loss: 0.3895\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.3694 - val_loss: 0.3875\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.3684 - val_loss: 0.3882\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 742us/step - loss: 0.3676 - val_loss: 0.3861\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 781us/step - loss: 0.3682 - val_loss: 0.3851\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3662 - val_loss: 0.3854\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3662 - val_loss: 0.3827\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3645 - val_loss: 0.3825\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.3632 - val_loss: 0.3809\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.3626 - val_loss: 0.3820\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.3615 - val_loss: 0.3829\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.3617 - val_loss: 0.3791\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.3603 - val_loss: 0.3788\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.3597 - val_loss: 0.3789\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.3584 - val_loss: 0.3772\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 752us/step - loss: 0.3579 - val_loss: 0.3761\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 750us/step - loss: 0.3574 - val_loss: 0.3766\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.3563 - val_loss: 0.3751\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.3576 - val_loss: 0.3744\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3551 - val_loss: 0.3750\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.3541 - val_loss: 0.3724\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.3535 - val_loss: 0.3706\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 756us/step - loss: 0.3535 - val_loss: 0.3695\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.3515 - val_loss: 0.3691\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 753us/step - loss: 0.3510 - val_loss: 0.3700\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.3509 - val_loss: 0.3712\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3509 - val_loss: 0.3687\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.3498 - val_loss: 0.3704\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3485 - val_loss: 0.3666\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 763us/step - loss: 0.3487 - val_loss: 0.3670\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.3498 - val_loss: 0.3652\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.3470 - val_loss: 0.3651\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 702us/step - loss: 0.3462 - val_loss: 0.3632\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.3449 - val_loss: 0.3639\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.3460 - val_loss: 0.3623\n",
      "162/162 [==============================] - 0s 588us/step - loss: 0.3573\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), \n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to train hundreds model and choose best model in validation set. Since there are lots of hyperparameters, random search is better than grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3114 - val_loss: 2.4800\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 1.6659 - val_loss: 1.1879\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0215 - val_loss: 0.9241\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.8551 - val_loss: 0.8153\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.7711 - val_loss: 0.7501\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.7193 - val_loss: 0.7080\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.6844 - val_loss: 0.6786\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.6594 - val_loss: 0.6572\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.6400 - val_loss: 0.6405\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.6240 - val_loss: 0.6266\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6150\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.5989 - val_loss: 0.6047\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5889 - val_loss: 0.5959\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5881\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - val_loss: 0.5807\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5649 - val_loss: 0.5744\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.5585 - val_loss: 0.5686\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5528 - val_loss: 0.5631\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5475 - val_loss: 0.5582\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.5426 - val_loss: 0.5535\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5383 - val_loss: 0.5492\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5343 - val_loss: 0.5454\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.5304 - val_loss: 0.5417\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5271 - val_loss: 0.5383\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5238 - val_loss: 0.5352\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5209 - val_loss: 0.5323\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5180 - val_loss: 0.5294\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5151 - val_loss: 0.5271\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 0.5244\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5104 - val_loss: 0.5221\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5081 - val_loss: 0.5196\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5059 - val_loss: 0.5175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.5038 - val_loss: 0.5154\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5018 - val_loss: 0.5135\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4999 - val_loss: 0.5117\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4980 - val_loss: 0.5102\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4963 - val_loss: 0.5084\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.4946 - val_loss: 0.5064\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4930 - val_loss: 0.5049\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4913 - val_loss: 0.5034\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4897 - val_loss: 0.5021\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4882 - val_loss: 0.5008\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4867 - val_loss: 0.4992\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4978\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.4964\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4827 - val_loss: 0.4953\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4814 - val_loss: 0.4940\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4798 - val_loss: 0.4933\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4788 - val_loss: 0.4918\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.4775 - val_loss: 0.4908\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4764 - val_loss: 0.4898\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.4751 - val_loss: 0.4888\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.4740 - val_loss: 0.4879\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4729 - val_loss: 0.4866\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4716 - val_loss: 0.4860\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4707 - val_loss: 0.4848\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4696 - val_loss: 0.4838\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4685 - val_loss: 0.4831\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.4675 - val_loss: 0.4821\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4813\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4655 - val_loss: 0.4805\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4645 - val_loss: 0.4794\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.4634 - val_loss: 0.4787\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4625 - val_loss: 0.4779\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4770\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4606 - val_loss: 0.4762\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4596 - val_loss: 0.4754\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4746\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.4578 - val_loss: 0.4738\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4568 - val_loss: 0.4729\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4725\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4552 - val_loss: 0.4714\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4542 - val_loss: 0.4706\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4532 - val_loss: 0.4699\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4524 - val_loss: 0.4692\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.4515 - val_loss: 0.4685\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4507 - val_loss: 0.4675\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4498 - val_loss: 0.4667\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4658\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4652\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.4473 - val_loss: 0.4644\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4465 - val_loss: 0.4640\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4458 - val_loss: 0.4631\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4625\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4616\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.4435 - val_loss: 0.4607\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4427 - val_loss: 0.4603\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4594\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4588\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4406 - val_loss: 0.4579\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4398 - val_loss: 0.4572\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4565\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4558\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4550\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4370 - val_loss: 0.4543\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4362 - val_loss: 0.4539\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4356 - val_loss: 0.4532\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4350 - val_loss: 0.4523\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.4343 - val_loss: 0.4516\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4335 - val_loss: 0.4511\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2785WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 759us/step - loss: 0.4538\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9787 - val_loss: 1.9484\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5981 - val_loss: 1.2367\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1514 - val_loss: 0.9629\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9417 - val_loss: 0.8326\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8278 - val_loss: 0.7608\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7623 - val_loss: 0.7204\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7207 - val_loss: 0.6941\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6923 - val_loss: 0.6752\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6713 - val_loss: 0.6600\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6546 - val_loss: 0.6473\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6405 - val_loss: 0.6359\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6282 - val_loss: 0.6259\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6176 - val_loss: 0.6162\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.6076\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.5996\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.5922\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5829 - val_loss: 0.5849\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.5758 - val_loss: 0.5782\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - val_loss: 0.5720\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.5627 - val_loss: 0.5661\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5567 - val_loss: 0.5604\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5509 - val_loss: 0.5548\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 0.5496\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5402 - val_loss: 0.5446\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5400\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.5355\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.5257 - val_loss: 0.5313\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5272\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5172 - val_loss: 0.5233\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5131 - val_loss: 0.5196\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5093 - val_loss: 0.5160\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.5126\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5022 - val_loss: 0.5095\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4988 - val_loss: 0.5064\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4956 - val_loss: 0.5035\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4925 - val_loss: 0.5008\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4896 - val_loss: 0.4982\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4868 - val_loss: 0.4959\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4935\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4816 - val_loss: 0.4913\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4791 - val_loss: 0.4891\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.4871\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.4851\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4722 - val_loss: 0.4832\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.4815\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4801\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4663 - val_loss: 0.4783\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4645 - val_loss: 0.4765\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.4753\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4610 - val_loss: 0.4738\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 0.4724\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4711\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4562 - val_loss: 0.4698\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4548 - val_loss: 0.4686\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4675\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4519 - val_loss: 0.4662\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4505 - val_loss: 0.4652\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4640\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4629\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4467 - val_loss: 0.4619\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4454 - val_loss: 0.4609\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4442 - val_loss: 0.4599\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4430 - val_loss: 0.4591\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.4580\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4573\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.4562\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4386 - val_loss: 0.4557\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4547\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4538\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4531\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4522\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4516\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4509\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4501\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4309 - val_loss: 0.4495\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4491\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4484\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4473\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4468\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4469\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4453\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4251 - val_loss: 0.4448\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.4243 - val_loss: 0.4439\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4238 - val_loss: 0.4434\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4229 - val_loss: 0.4429\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4222 - val_loss: 0.4422\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4214 - val_loss: 0.4417\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4208 - val_loss: 0.4408\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4200 - val_loss: 0.4403\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4403\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.4186 - val_loss: 0.4392\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4180 - val_loss: 0.4388\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4172 - val_loss: 0.4382\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4165 - val_loss: 0.4375\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.4158 - val_loss: 0.4373\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4153 - val_loss: 0.4365\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4145 - val_loss: 0.4361\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4141 - val_loss: 0.4355\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.4135 - val_loss: 0.4348\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.4343\n",
      "121/121 [==============================] - 0s 553us/step - loss: 0.4331\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2623 - val_loss: 2.9471\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3617 - val_loss: 1.6918\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6018 - val_loss: 1.2488\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 1.2301 - val_loss: 1.0320\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 1.0196 - val_loss: 0.9072\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.9008 - val_loss: 0.8290\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8272 - val_loss: 0.7768\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.7795 - val_loss: 0.7415\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.7465 - val_loss: 0.7163\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.7221 - val_loss: 0.6974\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.7034 - val_loss: 0.6821\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6878 - val_loss: 0.6688\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6744 - val_loss: 0.6570\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.6627 - val_loss: 0.6464\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6522 - val_loss: 0.6369\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.6426 - val_loss: 0.6277\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.6331 - val_loss: 0.6191\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6247 - val_loss: 0.6118\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6042\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.5970\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.6021 - val_loss: 0.5903\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5953 - val_loss: 0.5840\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.5889 - val_loss: 0.5785\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.5827 - val_loss: 0.5726\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.5768 - val_loss: 0.5671\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.5713 - val_loss: 0.5623\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5661 - val_loss: 0.5577\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.5610 - val_loss: 0.5535\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.5562 - val_loss: 0.5492\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5516 - val_loss: 0.5452\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.5472 - val_loss: 0.5416\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.5430 - val_loss: 0.5379\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.5390 - val_loss: 0.5344\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.5350 - val_loss: 0.5309\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.5315 - val_loss: 0.5280\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.5278 - val_loss: 0.5251\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.5244 - val_loss: 0.5222\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.5211 - val_loss: 0.5194\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.5180 - val_loss: 0.5169\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.5150 - val_loss: 0.5146\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.511 - 0s 938us/step - loss: 0.5121 - val_loss: 0.5123\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5092 - val_loss: 0.5097\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.5065 - val_loss: 0.5078\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.5041 - val_loss: 0.5059\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5016 - val_loss: 0.5038\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4991 - val_loss: 0.5017\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4968 - val_loss: 0.5003\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4947 - val_loss: 0.4985\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4925 - val_loss: 0.4966\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4905 - val_loss: 0.4952\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4885 - val_loss: 0.4935\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4866 - val_loss: 0.4920\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4848 - val_loss: 0.4906\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4830 - val_loss: 0.4896\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4814 - val_loss: 0.4880\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4797 - val_loss: 0.4866\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4781 - val_loss: 0.4854\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4766 - val_loss: 0.4842\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4752 - val_loss: 0.4831\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4737 - val_loss: 0.4821\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4722 - val_loss: 0.4817\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4710 - val_loss: 0.4800\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4696 - val_loss: 0.4793\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.4682 - val_loss: 0.4780\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4770\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.4658 - val_loss: 0.4764\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4646 - val_loss: 0.4753\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4634 - val_loss: 0.4749\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4622 - val_loss: 0.4737\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.4611 - val_loss: 0.4732\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4600 - val_loss: 0.4726\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4590 - val_loss: 0.4710\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4579 - val_loss: 0.4702\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4569 - val_loss: 0.4698\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4558 - val_loss: 0.4686\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4549 - val_loss: 0.4685\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.4540 - val_loss: 0.4675\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4531 - val_loss: 0.4668\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4522 - val_loss: 0.4660\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4654\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4505 - val_loss: 0.4647\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4496 - val_loss: 0.4643\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4487 - val_loss: 0.4633\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4480 - val_loss: 0.4628\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4632\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4464 - val_loss: 0.4623\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.4456 - val_loss: 0.4615\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4449 - val_loss: 0.4610\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4602\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4435 - val_loss: 0.4603\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4429 - val_loss: 0.4592\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.4586\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.4415 - val_loss: 0.4581\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4408 - val_loss: 0.4575\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4402 - val_loss: 0.4577\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4579\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.4390 - val_loss: 0.4566\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4383 - val_loss: 0.4558\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4377 - val_loss: 0.4559\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4370 - val_loss: 0.4550\n",
      "121/121 [==============================] - 0s 558us/step - loss: 0.4355\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 1.0122 - val_loss: 0.5715\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5571 - val_loss: 0.5381\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.5305 - val_loss: 0.5225\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5213 - val_loss: 0.5182\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.5181 - val_loss: 0.5164\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.5172 - val_loss: 0.5179\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5163 - val_loss: 0.5161\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5166 - val_loss: 0.5279\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.5150 - val_loss: 0.5309\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.5149 - val_loss: 0.5301\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.5159 - val_loss: 0.5161\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.5149 - val_loss: 0.5197\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.5140 - val_loss: 0.5252\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.5161 - val_loss: 0.5275\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.5157 - val_loss: 0.5243\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5159 - val_loss: 0.5215\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5166 - val_loss: 0.5194\n",
      "121/121 [==============================] - 0s 513us/step - loss: 0.7302\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 9.8320 - val_loss: 0.9920\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.9359 - val_loss: 0.5696\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 6.3944 - val_loss: 0.5075\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 1.0658 - val_loss: 0.5783\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 37.5421 - val_loss: 2.2847\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 33.4031 - val_loss: 1.0617\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 11.5446 - val_loss: 0.7341\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 30.2877 - val_loss: 1.1242\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 382.6129 - val_loss: 1.4357\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 138.4209 - val_loss: 5.9331\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 130.1522 - val_loss: 3.9675\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 848.4040 - val_loss: 10.1788\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 751.0648 - val_loss: 22.8386\n",
      "121/121 [==============================] - 0s 510us/step - loss: 323.1111\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 5.2773 - val_loss: 0.5556\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 1.8886 - val_loss: 0.5568\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 1.2106 - val_loss: 0.5762\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 1.0596 - val_loss: 0.4906\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 17.9223 - val_loss: 0.6678\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 36.8615 - val_loss: 0.6011\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 1.7528 - val_loss: 2.7730\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 3.2299 - val_loss: 0.5276\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 2.5946 - val_loss: 0.8711\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 131.2664 - val_loss: 0.6840\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 95.4627 - val_loss: 1.4306\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 244.2943 - val_loss: 0.8876\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 297.2162 - val_loss: 1.4027\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 16.6550 - val_loss: 1.6748\n",
      "121/121 [==============================] - 0s 485us/step - loss: 1.0698\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6907 - val_loss: 0.5442\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.5221 - val_loss: 0.5011\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.4965 - val_loss: 0.4911\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.4812 - val_loss: 0.4802\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4755 - val_loss: 0.4984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4696 - val_loss: 0.4734\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4651 - val_loss: 0.4662\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.4622 - val_loss: 0.4635\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4586 - val_loss: 0.4623\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.4543 - val_loss: 0.4609\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.4547 - val_loss: 0.4680\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4472 - val_loss: 0.4519\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4475 - val_loss: 0.4621\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4450 - val_loss: 0.4519\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4451 - val_loss: 0.4473\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4384 - val_loss: 0.4451\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.4341 - val_loss: 0.4540\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4349 - val_loss: 0.4436\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.4331 - val_loss: 0.4603\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.4290 - val_loss: 0.4452\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4263 - val_loss: 0.4328\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4246 - val_loss: 0.4296\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4221 - val_loss: 0.4257\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.4184 - val_loss: 0.4272\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4149 - val_loss: 0.4284\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4148 - val_loss: 0.4170\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4129 - val_loss: 0.4162\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4092 - val_loss: 0.4121\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4107 - val_loss: 0.4193\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4072 - val_loss: 0.4172\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4079 - val_loss: 0.4166\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4040 - val_loss: 0.4151\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4033 - val_loss: 0.4086\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4018 - val_loss: 0.4139\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3985 - val_loss: 0.4198\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3963 - val_loss: 0.4035\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3931 - val_loss: 0.4072\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3979 - val_loss: 0.4142\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3930 - val_loss: 0.4162\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3889 - val_loss: 0.4012\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3852 - val_loss: 0.4045\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3954 - val_loss: 0.4052\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3848 - val_loss: 0.3979\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3828 - val_loss: 0.4011\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3813 - val_loss: 0.4036\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3794 - val_loss: 0.4039\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3787 - val_loss: 0.3980\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.3813 - val_loss: 0.3978\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3767 - val_loss: 0.3975\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3785 - val_loss: 0.3908\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3773 - val_loss: 0.3968\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3780 - val_loss: 0.3907\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3740 - val_loss: 0.3972\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.3760 - val_loss: 0.3806\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3736 - val_loss: 0.3781\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3707 - val_loss: 0.3772\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3700 - val_loss: 0.3747\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3679 - val_loss: 0.3798\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3706 - val_loss: 0.3723\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3694 - val_loss: 0.3779\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3677 - val_loss: 0.3704\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3673 - val_loss: 0.3662\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3653 - val_loss: 0.3713\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3641 - val_loss: 0.3685\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3646 - val_loss: 0.3618\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3639 - val_loss: 0.3673\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3624 - val_loss: 0.3732\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3605 - val_loss: 0.3781\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3621 - val_loss: 0.3726\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3590 - val_loss: 0.3655\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3605 - val_loss: 0.3678\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3604 - val_loss: 0.3657\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3642 - val_loss: 0.3699\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3590 - val_loss: 0.3547\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3554 - val_loss: 0.3632\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3589 - val_loss: 0.3569\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3620 - val_loss: 0.3594\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3552 - val_loss: 0.3579\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.3545 - val_loss: 0.3646\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3580 - val_loss: 0.3642\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3534 - val_loss: 0.3636\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3579\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3586 - val_loss: 0.3613\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3503 - val_loss: 0.3567\n",
      "121/121 [==============================] - 0s 502us/step - loss: 0.3524\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6896 - val_loss: 0.5065\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.4783 - val_loss: 0.4725\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.4574 - val_loss: 0.4882\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4466 - val_loss: 0.4576\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4391 - val_loss: 0.4625\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4307 - val_loss: 0.4587\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4257 - val_loss: 0.4584\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.4240 - val_loss: 0.4566\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4178 - val_loss: 0.4418\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.4179 - val_loss: 0.4318\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4100 - val_loss: 0.4299\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4088 - val_loss: 0.4594\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4054 - val_loss: 0.4253\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4060 - val_loss: 0.4247\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.4035 - val_loss: 0.4296\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4029 - val_loss: 0.4240\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3991 - val_loss: 0.4137\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3993 - val_loss: 0.4288\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3967 - val_loss: 0.4153\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3944 - val_loss: 0.4197\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3926 - val_loss: 0.4100\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.3934 - val_loss: 0.4182\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3906 - val_loss: 0.4050\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4178 - val_loss: 0.4492\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.4183 - val_loss: 0.4167\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3883 - val_loss: 0.4012\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3824 - val_loss: 0.4070\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3818 - val_loss: 0.3963\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3758 - val_loss: 0.3974\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3962 - val_loss: 0.4112\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3851 - val_loss: 0.3985\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3787 - val_loss: 0.3945\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3747 - val_loss: 0.4062\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3711 - val_loss: 0.3870\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.3715 - val_loss: 0.4025\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3772 - val_loss: 0.3917\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3880 - val_loss: 0.3988\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3776 - val_loss: 0.4195\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3824 - val_loss: 0.3978\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3726 - val_loss: 0.3942\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3726 - val_loss: 0.3979\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3979 - val_loss: 0.4178\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3808 - val_loss: 0.4065\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3716 - val_loss: 0.3935\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2259WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 544us/step - loss: 0.3956\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7648 - val_loss: 0.5276\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.5077 - val_loss: 0.5006\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.4882 - val_loss: 0.4942\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4805 - val_loss: 0.4948\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5248 - val_loss: 0.6837\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5520 - val_loss: 0.5261\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4997 - val_loss: 0.4975\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.4800 - val_loss: 0.4829\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4737 - val_loss: 0.4733\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4580 - val_loss: 0.4638\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.4654 - val_loss: 0.4757\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.4558 - val_loss: 0.4769\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.4447 - val_loss: 0.4595\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.4402 - val_loss: 0.4484\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4364 - val_loss: 0.4452\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4304 - val_loss: 0.4413\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4306 - val_loss: 0.4501\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.4301 - val_loss: 0.4515\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.4232 - val_loss: 0.4363\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4198 - val_loss: 0.4361\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.4198 - val_loss: 0.4339\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4164 - val_loss: 0.4282\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4197 - val_loss: 0.4349\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.4181 - val_loss: 0.4352\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4139 - val_loss: 0.4233\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4124 - val_loss: 0.4347\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.4135 - val_loss: 0.4308\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4092 - val_loss: 0.4239\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.4175 - val_loss: 0.4295\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4114 - val_loss: 0.4308\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4072 - val_loss: 0.4170\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4123 - val_loss: 0.4528\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4106 - val_loss: 0.4219\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4036 - val_loss: 0.4216\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4085 - val_loss: 0.4473\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4087 - val_loss: 0.4206\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4019 - val_loss: 0.4272\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3977 - val_loss: 0.4149\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.3991 - val_loss: 0.4176\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3983 - val_loss: 0.4191\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.4203 - val_loss: 0.5341\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4448 - val_loss: 0.4410\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.4165 - val_loss: 0.4345\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.4076 - val_loss: 0.4232\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4004 - val_loss: 0.4212\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3966 - val_loss: 0.4184\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3963 - val_loss: 0.4171\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3932 - val_loss: 0.4117\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4050 - val_loss: 0.4160\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3931 - val_loss: 0.4086\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3911 - val_loss: 0.4138\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3951 - val_loss: 0.4107\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3918 - val_loss: 0.4169\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3900 - val_loss: 0.4151\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.5026 - val_loss: 0.5416\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4756 - val_loss: 0.4860\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4462 - val_loss: 0.4675\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4326 - val_loss: 0.4493\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4247 - val_loss: 0.4449\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.4172 - val_loss: 0.4360\n",
      "121/121 [==============================] - 0s 456us/step - loss: 0.4041\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 4.1065WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0346 - val_loss: 1.0440\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.8739 - val_loss: 0.7959\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.7544 - val_loss: 0.7321\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.7051 - val_loss: 0.6918\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.6693 - val_loss: 0.6601\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.6394 - val_loss: 0.6343\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.6138 - val_loss: 0.6117\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.5915 - val_loss: 0.5918\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5722 - val_loss: 0.5747\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.5556 - val_loss: 0.5605\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.5411 - val_loss: 0.5481\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.5284 - val_loss: 0.5377\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.5174 - val_loss: 0.5281\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5081 - val_loss: 0.5201\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.5001 - val_loss: 0.5137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4931 - val_loss: 0.5078\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4874 - val_loss: 0.5023\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4820 - val_loss: 0.4978\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4779 - val_loss: 0.4943\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4739 - val_loss: 0.4910\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4709 - val_loss: 0.4882\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4678 - val_loss: 0.4854\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4652 - val_loss: 0.4832\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.4629 - val_loss: 0.4805\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.4606 - val_loss: 0.4790\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4584 - val_loss: 0.4771\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4566 - val_loss: 0.4768\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4551 - val_loss: 0.4738\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.4535 - val_loss: 0.4727\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4520 - val_loss: 0.4706\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4503 - val_loss: 0.4694\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4489 - val_loss: 0.4688\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4478 - val_loss: 0.4676\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4465 - val_loss: 0.4659\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.4452 - val_loss: 0.4648\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4441 - val_loss: 0.4638\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4430 - val_loss: 0.4626\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4419 - val_loss: 0.4616\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4405 - val_loss: 0.4603\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4398 - val_loss: 0.4594\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.4387 - val_loss: 0.4584\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.4376 - val_loss: 0.4575\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4369 - val_loss: 0.4568\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4358 - val_loss: 0.4563\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4349 - val_loss: 0.4550\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4340 - val_loss: 0.4549\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.4331 - val_loss: 0.4534\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4323 - val_loss: 0.4520\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4314 - val_loss: 0.4515\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.4306 - val_loss: 0.4511\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4298 - val_loss: 0.4500\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4291 - val_loss: 0.4494\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4282 - val_loss: 0.4489\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4274 - val_loss: 0.4483\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4267 - val_loss: 0.4475\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4261 - val_loss: 0.4465\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4254 - val_loss: 0.4456\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4246 - val_loss: 0.4451\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4238 - val_loss: 0.4446\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4231 - val_loss: 0.4439\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4225 - val_loss: 0.4432\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4218 - val_loss: 0.4424\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4210 - val_loss: 0.4418\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4203 - val_loss: 0.4410\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4198 - val_loss: 0.4412\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.4191 - val_loss: 0.4400\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4186 - val_loss: 0.4397\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4178 - val_loss: 0.4389\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4174 - val_loss: 0.4391\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4166 - val_loss: 0.4384\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4161 - val_loss: 0.4368\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4155 - val_loss: 0.4360\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4149 - val_loss: 0.4361\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4145 - val_loss: 0.4352\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4138 - val_loss: 0.4351\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4130 - val_loss: 0.4348\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4127 - val_loss: 0.4333\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4122 - val_loss: 0.4336\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4114 - val_loss: 0.4333\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4111 - val_loss: 0.4320\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4316\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4306\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4093 - val_loss: 0.4308\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4308\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.4297\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4287\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4283\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4281\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4273\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.4057 - val_loss: 0.4270\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4271\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4253\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4043 - val_loss: 0.4256\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.4260\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4246\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4237\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4242\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.4226\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4233\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4215\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2567WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 623us/step - loss: 0.4690\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1707 - val_loss: 0.9229\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.8087 - val_loss: 0.7246\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.6889 - val_loss: 0.6657\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.6309 - val_loss: 0.6196\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.5924 - val_loss: 0.5877\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5676 - val_loss: 0.5652\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.5481 - val_loss: 0.5470\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.5349 - val_loss: 0.5372\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5233 - val_loss: 0.5251\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5133 - val_loss: 0.5178\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.5045 - val_loss: 0.5086\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5005 - val_loss: 0.5062\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4939 - val_loss: 0.4985\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4884 - val_loss: 0.4964\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4855 - val_loss: 0.4906\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4840 - val_loss: 0.4895\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4793 - val_loss: 0.4867\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4735 - val_loss: 0.4814\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4732 - val_loss: 0.4812\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.4702 - val_loss: 0.4800\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4652 - val_loss: 0.4764\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4646 - val_loss: 0.4742\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4632 - val_loss: 0.4721\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4594 - val_loss: 0.4717\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4581 - val_loss: 0.4693\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4577 - val_loss: 0.4685\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4550 - val_loss: 0.4657\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.4528 - val_loss: 0.4661\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4522 - val_loss: 0.4632\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4521 - val_loss: 0.4636\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.4490 - val_loss: 0.4609\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4480 - val_loss: 0.4610\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4504 - val_loss: 0.4585\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.4451 - val_loss: 0.4568\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.4566\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4544\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4398 - val_loss: 0.4542\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4413 - val_loss: 0.4529\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4372 - val_loss: 0.4522\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4375 - val_loss: 0.4490\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4375 - val_loss: 0.4505\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4485\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4344 - val_loss: 0.4476\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4330 - val_loss: 0.4463\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4310 - val_loss: 0.4463\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4316 - val_loss: 0.4454\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4299 - val_loss: 0.4436\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4425\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4426\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4409\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4401\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4400\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4266 - val_loss: 0.4382\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4229 - val_loss: 0.4380\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.4232 - val_loss: 0.4357\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4366\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4362\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4358\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4340\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4336\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4331\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.4325\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.4165 - val_loss: 0.4311\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4164 - val_loss: 0.4307\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4140 - val_loss: 0.4305\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4296\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4290\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4117 - val_loss: 0.4292\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4125 - val_loss: 0.4285\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4110 - val_loss: 0.4271\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4272\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.4262\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4252\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4092 - val_loss: 0.4269\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4096 - val_loss: 0.4245\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4241\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4058 - val_loss: 0.4249\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.4232\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.4225\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4218\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4208\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4210\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4199\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4193\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4186\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4017 - val_loss: 0.4180\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.4185\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3996 - val_loss: 0.4168\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4005 - val_loss: 0.4173\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4006 - val_loss: 0.4169\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3978 - val_loss: 0.4160\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3977 - val_loss: 0.4154\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3962 - val_loss: 0.4149\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3965 - val_loss: 0.4151\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3959 - val_loss: 0.4141\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3945 - val_loss: 0.4127\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3935 - val_loss: 0.4141\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3940 - val_loss: 0.4118\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3935 - val_loss: 0.4122\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3918 - val_loss: 0.4122\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.1873WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 552us/step - loss: 0.4156\n",
      "Epoch 1/100\n",
      "241/242 [============================>.] - ETA: 0s - loss: 1.9326WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9276 - val_loss: 0.7876\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.7505 - val_loss: 0.6859\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.6895 - val_loss: 0.6506\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.6531 - val_loss: 0.6200\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.6236 - val_loss: 0.5948\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5997 - val_loss: 0.5746\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.5783 - val_loss: 0.5577\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.5593 - val_loss: 0.5467\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5445 - val_loss: 0.5321\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.5287 - val_loss: 0.5201\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5214 - val_loss: 0.5105\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.5105 - val_loss: 0.5020\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.5028 - val_loss: 0.4968\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4951 - val_loss: 0.4944\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4885 - val_loss: 0.4865\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4856 - val_loss: 0.4902\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4800 - val_loss: 0.4809\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4775 - val_loss: 0.4822\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4740 - val_loss: 0.4767\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4709 - val_loss: 0.4761\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4685 - val_loss: 0.4753\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.4654 - val_loss: 0.4714\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4623 - val_loss: 0.4694\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4616 - val_loss: 0.4668\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4613 - val_loss: 0.4665\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4574 - val_loss: 0.4635\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4562 - val_loss: 0.4674\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4539 - val_loss: 0.4647\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4508 - val_loss: 0.4613\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4511 - val_loss: 0.4633\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4486 - val_loss: 0.4627\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4464 - val_loss: 0.4576\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4470 - val_loss: 0.4569\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4447 - val_loss: 0.4563\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4419 - val_loss: 0.4625\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4421 - val_loss: 0.4528\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4402 - val_loss: 0.4516\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.4390 - val_loss: 0.4523\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4391 - val_loss: 0.4527\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4370 - val_loss: 0.4502\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4360 - val_loss: 0.4499\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4349 - val_loss: 0.4496\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4334 - val_loss: 0.4472\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.4318 - val_loss: 0.4465\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4309 - val_loss: 0.4450\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4303 - val_loss: 0.4443\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4304 - val_loss: 0.4446\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4279 - val_loss: 0.4442\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4272 - val_loss: 0.4417\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.4265 - val_loss: 0.4426\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4258 - val_loss: 0.4416\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4240 - val_loss: 0.4457\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4232 - val_loss: 0.4394\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4226 - val_loss: 0.4412\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4218 - val_loss: 0.4378\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.4202 - val_loss: 0.4371\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4191 - val_loss: 0.4371\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4187 - val_loss: 0.4381\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4184 - val_loss: 0.4356\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4167 - val_loss: 0.4370\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4171 - val_loss: 0.4345\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4157 - val_loss: 0.4341\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.4148 - val_loss: 0.4331\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4146 - val_loss: 0.4325\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.4134 - val_loss: 0.4324\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4129 - val_loss: 0.4325\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4120 - val_loss: 0.4315\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4119 - val_loss: 0.4308\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4111 - val_loss: 0.4303\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4101 - val_loss: 0.4300\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4100 - val_loss: 0.4302\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4092 - val_loss: 0.4288\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4084 - val_loss: 0.4290\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4075 - val_loss: 0.4293\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.4074 - val_loss: 0.4284\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4064 - val_loss: 0.4273\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4062 - val_loss: 0.4268\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4050 - val_loss: 0.4271\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4049 - val_loss: 0.4255\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4037 - val_loss: 0.4249\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4042 - val_loss: 0.4237\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4026 - val_loss: 0.4243\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4024 - val_loss: 0.4242\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4013 - val_loss: 0.4233\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4012 - val_loss: 0.4225\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4005 - val_loss: 0.4235\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3999 - val_loss: 0.4230\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3994 - val_loss: 0.4230\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3990 - val_loss: 0.4232\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3988 - val_loss: 0.4214\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3977 - val_loss: 0.4214\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3973 - val_loss: 0.4215\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3970 - val_loss: 0.4200\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3962 - val_loss: 0.4199\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3960 - val_loss: 0.4198\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3954 - val_loss: 0.4185\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3958 - val_loss: 0.4203\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3952 - val_loss: 0.4181\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3939 - val_loss: 0.4176\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3935 - val_loss: 0.4179\n",
      "121/121 [==============================] - 0s 536us/step - loss: 0.3948\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7467 - val_loss: 0.7995\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7104 - val_loss: 0.6393\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6192 - val_loss: 0.5872\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.5534\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5412 - val_loss: 0.5294\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.5133\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5000 - val_loss: 0.4971\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4860 - val_loss: 0.4854\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4737 - val_loss: 0.4760\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4645 - val_loss: 0.4678\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4615\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4496 - val_loss: 0.4614\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4524\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4481\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4348 - val_loss: 0.4459\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4429\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4396\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4377\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4343\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4320\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4298\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.4295\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4278\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4236\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.4220\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4201\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4188\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4165\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.4155\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4185\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.4109\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4100\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4090\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4070\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.4044\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4041\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.4032\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3998\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.4030\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3975\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3982\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3962\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3938\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3926\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3938\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3918\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3892\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3910\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3890\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.3859\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3849\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3828\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3830\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3807\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.3813\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.3829\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3798\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3767\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3769\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.3748\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3733\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3732\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.3745\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.3740\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3733\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3690\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3704\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3698\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3685\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3687\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3651\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3646\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.3669\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.3618\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3621\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3620\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3592\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3584\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3583\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3585\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.3575\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3579\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3572\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3572\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3251 - val_loss: 0.3549\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.3542\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3510\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3521\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3511\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3208 - val_loss: 0.3512\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3505\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3482\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3487\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3478\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3480\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3474\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3463\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3469\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3442\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3479\n",
      "121/121 [==============================] - 0s 577us/step - loss: 0.3232\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8336 - val_loss: 0.7974\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7054 - val_loss: 0.6666\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6308 - val_loss: 0.6220\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5898 - val_loss: 0.5869\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5565 - val_loss: 0.5578\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5314\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.5109\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4896 - val_loss: 0.4950\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4754 - val_loss: 0.4819\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4737\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4537 - val_loss: 0.4640\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4585\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4388 - val_loss: 0.4517\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4500\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4460\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4404\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4380\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.4341\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.4332\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4301\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4276\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4269\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4231\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4207\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4190\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.4168\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4156\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4131\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.4112\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4107\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4093\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.4072\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4050\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.4032\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4021\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.4002\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.3996\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3972\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3956\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3956\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.3939\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3927\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3908\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3888\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3871\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3858\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3846\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3870\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3822\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3804\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3805\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3782\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3775\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.3770\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3766\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3744\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3745\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.3738\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3709\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3726\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.3714\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3681\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.3667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3659\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3656\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3632\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3648\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3614\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.3619\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3614\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3588\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3572\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3594\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3187 - val_loss: 0.3563\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.3560\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3550\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3530\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.3521\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3527\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.3508\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3578\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3505\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3486\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3482\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.3474\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3463\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3468\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3449\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3456\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3448\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3430\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3436\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3454\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3419\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.3451\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.3400\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.3392\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3405\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3400\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.3402\n",
      "121/121 [==============================] - 0s 569us/step - loss: 0.3390\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8029 - val_loss: 0.7116\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6849 - val_loss: 0.6268\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.5723\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 0.5393\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5324 - val_loss: 0.5146\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.5010\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4905 - val_loss: 0.4827\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4752 - val_loss: 0.4739\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.4718\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4619\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4590\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4491\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.4368 - val_loss: 0.4447\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4417\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4386\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4351\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4315\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4302\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.4294\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4254\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4236\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4217\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.4232\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4187\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4177\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4157\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4133\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4164\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.383 - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4096\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.4096\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4068\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4086\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.4073\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4026\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4052\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.4005\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.4032\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3981\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.3961\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3946\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.3967\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3925\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.3906\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3963\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3889\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.3891\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3905\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3856\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3866\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.3859\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3816\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3863\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3838\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3857\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3777\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3800\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3751\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3758\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3717\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3734\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3724\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3702\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3692\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3690\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3668\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3383 - val_loss: 0.3659\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3357 - val_loss: 0.3740\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.3643\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.3635\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3332 - val_loss: 0.3695\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3315 - val_loss: 0.3670\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3315 - val_loss: 0.3669\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3300 - val_loss: 0.3601\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3584\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3578\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3611\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3562\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3549\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3544\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.3575\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.3545\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3546\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3508\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3191 - val_loss: 0.3489\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3490\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3591\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.3687\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.3505\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3458\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3452\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3448\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3476\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.3440\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3421\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3422\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3095 - val_loss: 0.3395\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3432\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3408\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3426\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.3374\n",
      "121/121 [==============================] - 0s 577us/step - loss: 0.3175\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.3234 - val_loss: 4.0227\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 3.0094 - val_loss: 2.3330\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 1.8322 - val_loss: 1.4786\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 1.2288 - val_loss: 1.0417\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.9174 - val_loss: 0.8172\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.7552 - val_loss: 0.7011\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.6698 - val_loss: 0.6403\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.6240 - val_loss: 0.6077\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5987 - val_loss: 0.5901\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5842 - val_loss: 0.5799\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.5754 - val_loss: 0.5738\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.5697 - val_loss: 0.5696\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5655 - val_loss: 0.5666\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5623 - val_loss: 0.5641\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5596 - val_loss: 0.5619\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5573 - val_loss: 0.5599\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5551 - val_loss: 0.5581\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.5531 - val_loss: 0.5563\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5512 - val_loss: 0.5546\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.5494 - val_loss: 0.5530\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.5477 - val_loss: 0.5515\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5460 - val_loss: 0.5500\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5445 - val_loss: 0.5486\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.5430 - val_loss: 0.5473\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.5416 - val_loss: 0.5460\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5403 - val_loss: 0.5447\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5390 - val_loss: 0.5435\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5378 - val_loss: 0.5423\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.5367 - val_loss: 0.5412\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5355 - val_loss: 0.5402\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.5345 - val_loss: 0.5392\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5334 - val_loss: 0.5383\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5325 - val_loss: 0.5374\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.5316 - val_loss: 0.5366\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5307 - val_loss: 0.5357\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5298 - val_loss: 0.5350\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5290 - val_loss: 0.5342\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.5283 - val_loss: 0.5335\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.5275 - val_loss: 0.5328\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.5268 - val_loss: 0.5321\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5262 - val_loss: 0.5315\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5255 - val_loss: 0.5309\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.5249 - val_loss: 0.5303\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5244 - val_loss: 0.5298\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.5238 - val_loss: 0.5293\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.5233 - val_loss: 0.5288\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5228 - val_loss: 0.5283\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5223 - val_loss: 0.5279\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5218 - val_loss: 0.5274\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.5214 - val_loss: 0.5271\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.5209 - val_loss: 0.5267\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.5206 - val_loss: 0.5264\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5202 - val_loss: 0.5260\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5198 - val_loss: 0.5256\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5195 - val_loss: 0.5253\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5192 - val_loss: 0.5250\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5188 - val_loss: 0.5246\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.5185 - val_loss: 0.5245\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5182 - val_loss: 0.5242\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5179 - val_loss: 0.5238\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.5177 - val_loss: 0.5237\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5174 - val_loss: 0.5235\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5172 - val_loss: 0.5232\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5170 - val_loss: 0.5230\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5168 - val_loss: 0.5228\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5165 - val_loss: 0.5226\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.5163 - val_loss: 0.5224\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.5162 - val_loss: 0.5221\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5160 - val_loss: 0.5220\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5158 - val_loss: 0.5219\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5156 - val_loss: 0.5218\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5155 - val_loss: 0.5217\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.5153 - val_loss: 0.5216\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5152 - val_loss: 0.5214\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5151 - val_loss: 0.5213\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.5149 - val_loss: 0.5212\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5148 - val_loss: 0.5210\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.5147 - val_loss: 0.5209\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5146 - val_loss: 0.5208\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5145 - val_loss: 0.5207\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5144 - val_loss: 0.5206\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5143 - val_loss: 0.5206\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.5142 - val_loss: 0.5204\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5141 - val_loss: 0.5203\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.5140 - val_loss: 0.5202\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5139 - val_loss: 0.5201\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5138 - val_loss: 0.5201\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5137 - val_loss: 0.5201\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5137 - val_loss: 0.5201\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5136 - val_loss: 0.5200\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.5135 - val_loss: 0.5199\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5135 - val_loss: 0.5199\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5134 - val_loss: 0.5198\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5133 - val_loss: 0.5196\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.5133 - val_loss: 0.5196\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5132 - val_loss: 0.5197\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5132 - val_loss: 0.5196\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5131 - val_loss: 0.5196\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5131 - val_loss: 0.5195\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5131 - val_loss: 0.5195\n",
      "121/121 [==============================] - 0s 478us/step - loss: 0.7268\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 10.2748WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9030 - val_loss: 3.3635\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 2.6334 - val_loss: 1.9604\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 1.6118 - val_loss: 1.2987\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 1.1214 - val_loss: 0.9710\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.8758 - val_loss: 0.8040\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.7491 - val_loss: 0.7171\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.6817 - val_loss: 0.6704\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.6446 - val_loss: 0.6447\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.6234 - val_loss: 0.6296\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.6105 - val_loss: 0.6199\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.6021 - val_loss: 0.6135\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5960 - val_loss: 0.6091\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.5913 - val_loss: 0.6049\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5873 - val_loss: 0.6014\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.5839 - val_loss: 0.5986\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.5808 - val_loss: 0.5961\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5779 - val_loss: 0.5937\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5751 - val_loss: 0.5909\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5725 - val_loss: 0.5881\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5701 - val_loss: 0.5864\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.5677 - val_loss: 0.5836\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5656 - val_loss: 0.5816\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.5634 - val_loss: 0.5800\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.5614 - val_loss: 0.5779\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.5595 - val_loss: 0.5759\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5577 - val_loss: 0.5739\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5560 - val_loss: 0.5728\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5543 - val_loss: 0.5707\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5526 - val_loss: 0.5688\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5512 - val_loss: 0.5676\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.5497 - val_loss: 0.5661\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.5484 - val_loss: 0.5654\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.5470 - val_loss: 0.5641\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5458 - val_loss: 0.5628\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.5445 - val_loss: 0.5627\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5434 - val_loss: 0.5612\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5422 - val_loss: 0.5594\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.5413 - val_loss: 0.5584\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.5403 - val_loss: 0.5577\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5393 - val_loss: 0.5574\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5384 - val_loss: 0.5568\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.5375 - val_loss: 0.5552\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.5367 - val_loss: 0.5550\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.5360 - val_loss: 0.5538\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5519\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5345 - val_loss: 0.5523\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5335 - val_loss: 0.5507\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5330 - val_loss: 0.5516\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5324 - val_loss: 0.5502\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5316 - val_loss: 0.5485\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5313 - val_loss: 0.5492\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5306 - val_loss: 0.5492\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.5301 - val_loss: 0.5481\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.5296 - val_loss: 0.5478\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.5289 - val_loss: 0.5461\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.5287 - val_loss: 0.5465\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5281 - val_loss: 0.5455\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5277 - val_loss: 0.5465\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5273 - val_loss: 0.5455\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5267 - val_loss: 0.5440\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.5265 - val_loss: 0.5434\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5258 - val_loss: 0.5432\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5259 - val_loss: 0.5432\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.5253 - val_loss: 0.5419\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.5251 - val_loss: 0.5436\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.5248 - val_loss: 0.5432\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5245 - val_loss: 0.5423\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5241 - val_loss: 0.5413\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5239 - val_loss: 0.5407\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5238 - val_loss: 0.5408\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.5235 - val_loss: 0.5410\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5232 - val_loss: 0.5406\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.5230 - val_loss: 0.5403\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5228 - val_loss: 0.5415\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5225 - val_loss: 0.5401\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5224 - val_loss: 0.5397\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5220 - val_loss: 0.5390\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5220 - val_loss: 0.5406\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5218 - val_loss: 0.5401\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5214 - val_loss: 0.5386\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.5215 - val_loss: 0.5385\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5213 - val_loss: 0.5397\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5208 - val_loss: 0.5380\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5211 - val_loss: 0.5393\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5209 - val_loss: 0.5395\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.5206 - val_loss: 0.5383\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.5205 - val_loss: 0.5377\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5204 - val_loss: 0.5374\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5204 - val_loss: 0.5373\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5203 - val_loss: 0.5385\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.5201 - val_loss: 0.5387\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.5198 - val_loss: 0.5372\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.5199 - val_loss: 0.5372\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.5197 - val_loss: 0.5365\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5197 - val_loss: 0.5366\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5196 - val_loss: 0.5368\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5195 - val_loss: 0.5381\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.5195 - val_loss: 0.5379\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.5193 - val_loss: 0.5375\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.5192 - val_loss: 0.5373\n",
      "121/121 [==============================] - 0s 511us/step - loss: 0.5354\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.8659 - val_loss: 4.5936\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 3.6867 - val_loss: 2.4546\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 2.0310 - val_loss: 1.5069\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 1.3065 - val_loss: 1.0551\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.9619 - val_loss: 0.8311\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.7904 - val_loss: 0.7171\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.7022 - val_loss: 0.6580\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.6554 - val_loss: 0.6267\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.6295 - val_loss: 0.6093\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.6145 - val_loss: 0.5991\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.6050 - val_loss: 0.5925\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5985 - val_loss: 0.5878\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5937 - val_loss: 0.5842\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5897 - val_loss: 0.5812\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5863 - val_loss: 0.5784\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.5833 - val_loss: 0.5760\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5805 - val_loss: 0.5735\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5779 - val_loss: 0.5713\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5754 - val_loss: 0.5691\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5731 - val_loss: 0.5671\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5710 - val_loss: 0.5652\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.5689 - val_loss: 0.5634\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5669 - val_loss: 0.5617\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5651 - val_loss: 0.5601\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5633 - val_loss: 0.5587\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5616 - val_loss: 0.5572\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5600 - val_loss: 0.5561\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.5586 - val_loss: 0.5547\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.5571 - val_loss: 0.5534\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5557 - val_loss: 0.5520\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.5545 - val_loss: 0.5508\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5533 - val_loss: 0.5501\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5521 - val_loss: 0.5491\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.5510 - val_loss: 0.5482\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.5499 - val_loss: 0.5473\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5489 - val_loss: 0.5463\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.5480 - val_loss: 0.5456\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5471 - val_loss: 0.5453\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5462 - val_loss: 0.5441\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5455 - val_loss: 0.5436\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5447 - val_loss: 0.5434\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.5439 - val_loss: 0.5424\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.5432 - val_loss: 0.5423\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.5426 - val_loss: 0.5416\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5419 - val_loss: 0.5411\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5414 - val_loss: 0.5405\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.5408 - val_loss: 0.5400\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.5403 - val_loss: 0.5395\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5397 - val_loss: 0.5396\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5393 - val_loss: 0.5390\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.5389 - val_loss: 0.5387\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5383 - val_loss: 0.5377\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5380 - val_loss: 0.5382\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.5376 - val_loss: 0.5387\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.5373 - val_loss: 0.5381\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5368 - val_loss: 0.5369\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.5366 - val_loss: 0.5370\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5361 - val_loss: 0.5360\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.5359 - val_loss: 0.5367\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5356 - val_loss: 0.5359\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.5354 - val_loss: 0.5366\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5351 - val_loss: 0.5370\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5349 - val_loss: 0.5361\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.5345 - val_loss: 0.5352\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5345 - val_loss: 0.5361\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.5341 - val_loss: 0.5350\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5341 - val_loss: 0.5359\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5338 - val_loss: 0.5361\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5336 - val_loss: 0.5352\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.5334 - val_loss: 0.5345\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5333 - val_loss: 0.5345\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5332 - val_loss: 0.5349\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5329 - val_loss: 0.5343\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5328 - val_loss: 0.5339\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5328 - val_loss: 0.5348\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5325 - val_loss: 0.5339\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5326 - val_loss: 0.5350\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5324 - val_loss: 0.5353\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5322 - val_loss: 0.5359\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5321 - val_loss: 0.5359\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5320 - val_loss: 0.5346\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.5320 - val_loss: 0.5351\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5319 - val_loss: 0.5356\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5319 - val_loss: 0.5354\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.5318 - val_loss: 0.5349\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5317 - val_loss: 0.5348\n",
      "121/121 [==============================] - 0s 536us/step - loss: 0.5066\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2343 - val_loss: 0.9140\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.7982 - val_loss: 0.7728\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.7331 - val_loss: 0.7368\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7014 - val_loss: 0.7090\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.6758 - val_loss: 0.6851\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.6534 - val_loss: 0.6644\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.6339 - val_loss: 0.6466\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.6170 - val_loss: 0.6301\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.6021 - val_loss: 0.6159\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5888 - val_loss: 0.6036\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.5769 - val_loss: 0.5921\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5665 - val_loss: 0.5820\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5574 - val_loss: 0.5732\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5491 - val_loss: 0.5649\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.5576\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.5351 - val_loss: 0.5507\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5291 - val_loss: 0.5449\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5239 - val_loss: 0.5401\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.5192 - val_loss: 0.5355\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.5149 - val_loss: 0.5317\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5106 - val_loss: 0.5276\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.5073 - val_loss: 0.5241\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5036 - val_loss: 0.5215\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5006 - val_loss: 0.5181\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4978 - val_loss: 0.5154\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4951 - val_loss: 0.5124\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4925 - val_loss: 0.5104\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4902 - val_loss: 0.5076\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4882 - val_loss: 0.5054\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4863 - val_loss: 0.5037\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.4844 - val_loss: 0.5015\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4826 - val_loss: 0.4996\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4810 - val_loss: 0.4978\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4793 - val_loss: 0.4961\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.4780 - val_loss: 0.4946\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4767 - val_loss: 0.4934\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4754 - val_loss: 0.4918\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4743 - val_loss: 0.4909\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4733 - val_loss: 0.4901\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4723 - val_loss: 0.4895\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4713 - val_loss: 0.4876\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4705 - val_loss: 0.4864\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.4697 - val_loss: 0.4864\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4690 - val_loss: 0.4852\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4682 - val_loss: 0.4852\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4674 - val_loss: 0.4840\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4668 - val_loss: 0.4837\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4661 - val_loss: 0.4825\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4655 - val_loss: 0.4814\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4650 - val_loss: 0.4809\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4645 - val_loss: 0.4805\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.4640 - val_loss: 0.4799\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4634 - val_loss: 0.4800\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4629 - val_loss: 0.4787\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4624 - val_loss: 0.4783\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4620 - val_loss: 0.4783\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4614 - val_loss: 0.4771\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.4611 - val_loss: 0.4767\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.4604 - val_loss: 0.4775\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4602 - val_loss: 0.4764\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4597 - val_loss: 0.4756\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4591 - val_loss: 0.4749\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4749\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4580 - val_loss: 0.4739\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4574 - val_loss: 0.4733\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4569 - val_loss: 0.4731\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4564 - val_loss: 0.4724\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4558 - val_loss: 0.4718\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4715\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4549 - val_loss: 0.4710\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4545 - val_loss: 0.4702\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4700\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4535 - val_loss: 0.4693\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.4530 - val_loss: 0.4690\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4525 - val_loss: 0.4683\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4522 - val_loss: 0.4679\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4517 - val_loss: 0.4677\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4511 - val_loss: 0.4675\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.4508 - val_loss: 0.4666\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.4503 - val_loss: 0.4660\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4499 - val_loss: 0.4662\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4494 - val_loss: 0.4656\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4491 - val_loss: 0.4650\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4485 - val_loss: 0.4642\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4480 - val_loss: 0.4640\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4476 - val_loss: 0.4634\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4472 - val_loss: 0.4637\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4468 - val_loss: 0.4627\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4462 - val_loss: 0.4631\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4459 - val_loss: 0.4625\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.4455 - val_loss: 0.4616\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4451 - val_loss: 0.4615\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4446 - val_loss: 0.4607\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4442 - val_loss: 0.4607\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4437 - val_loss: 0.4603\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4434 - val_loss: 0.4596\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4430 - val_loss: 0.4593\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4425 - val_loss: 0.4593\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4423 - val_loss: 0.4584\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4418 - val_loss: 0.4579\n",
      "121/121 [==============================] - 0s 511us/step - loss: 0.4701\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6595 - val_loss: 1.6496\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 1.2836 - val_loss: 1.0499\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.9246 - val_loss: 0.8544\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.8006 - val_loss: 0.7709\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.7411 - val_loss: 0.7216\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.7013 - val_loss: 0.6898\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.6741 - val_loss: 0.6638\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6496 - val_loss: 0.6434\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.6296 - val_loss: 0.6242\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.6120 - val_loss: 0.6080\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5957 - val_loss: 0.5939\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5833 - val_loss: 0.5816\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.5703 - val_loss: 0.5709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.5584 - val_loss: 0.5603\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5494 - val_loss: 0.5518\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5412 - val_loss: 0.5443\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.5339 - val_loss: 0.5423\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.5239 - val_loss: 0.5315\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.5222 - val_loss: 0.5270\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5170 - val_loss: 0.5222\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5128 - val_loss: 0.5185\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.5085 - val_loss: 0.5161\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.5048 - val_loss: 0.5216\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4972 - val_loss: 0.5082\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4976 - val_loss: 0.5203\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4965 - val_loss: 0.5085\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.5014\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4911 - val_loss: 0.5027\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4886 - val_loss: 0.5003\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4846 - val_loss: 0.5088\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4836 - val_loss: 0.4944\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4814 - val_loss: 0.5009\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4793 - val_loss: 0.4904\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4791 - val_loss: 0.4897\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.4777 - val_loss: 0.4913\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.4872\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4741 - val_loss: 0.4852\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4735 - val_loss: 0.4861\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4702 - val_loss: 0.4824\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4699 - val_loss: 0.4896\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4704 - val_loss: 0.4939\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4672 - val_loss: 0.4803\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4669 - val_loss: 0.4795\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.4662 - val_loss: 0.4788\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4654 - val_loss: 0.4812\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4609 - val_loss: 0.4754\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.4632 - val_loss: 0.4882\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4605 - val_loss: 0.4744\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.4611 - val_loss: 0.4739\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4597 - val_loss: 0.4779\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4593 - val_loss: 0.4750\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.4580 - val_loss: 0.4749\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.4717\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4556 - val_loss: 0.4695\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4562 - val_loss: 0.4693\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4685\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4542 - val_loss: 0.4719\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4675\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4530 - val_loss: 0.4734\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4517 - val_loss: 0.4725\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4512 - val_loss: 0.4663\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4501 - val_loss: 0.4648\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4503 - val_loss: 0.4702\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4493 - val_loss: 0.4679\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4642\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4630\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4625\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4644\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4455 - val_loss: 0.4622\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4445 - val_loss: 0.4611\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4442 - val_loss: 0.4603\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4438 - val_loss: 0.4628\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4422 - val_loss: 0.4594\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4589\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4608\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4638\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4411 - val_loss: 0.4591\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.4399 - val_loss: 0.4569\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4400 - val_loss: 0.4568\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4388 - val_loss: 0.4554\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4391 - val_loss: 0.4565\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4382 - val_loss: 0.4557\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4566\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4584\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4366 - val_loss: 0.4546\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4351 - val_loss: 0.4529\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4366 - val_loss: 0.4529\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4356 - val_loss: 0.4527\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.4349 - val_loss: 0.4537\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.4344 - val_loss: 0.4524\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4332 - val_loss: 0.4509\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.4333 - val_loss: 0.4514\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4328 - val_loss: 0.4513\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4318 - val_loss: 0.4498\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4313 - val_loss: 0.4508\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4299 - val_loss: 0.4487\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.4305 - val_loss: 0.4488\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4299 - val_loss: 0.4486\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.4292 - val_loss: 0.4474\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.4289 - val_loss: 0.4497\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2399WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 484us/step - loss: 0.4556\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 3.0117 - val_loss: 1.1774\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 1.0274 - val_loss: 0.8433\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.8119 - val_loss: 0.7556\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.7475 - val_loss: 0.7189\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.7171 - val_loss: 0.7010\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.6965 - val_loss: 0.6828\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.6798 - val_loss: 0.6663\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.6661 - val_loss: 0.6551\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.6530 - val_loss: 0.6434\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.6417 - val_loss: 0.6343\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.6307 - val_loss: 0.6225\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.6222 - val_loss: 0.6166\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.6130 - val_loss: 0.6095\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.6033 - val_loss: 0.5982\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.5964 - val_loss: 0.5960\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.5883 - val_loss: 0.5858\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.5812 - val_loss: 0.5789\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.5744 - val_loss: 0.5722\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.5683 - val_loss: 0.5721\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.5612 - val_loss: 0.5610\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5561 - val_loss: 0.5566\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.5501 - val_loss: 0.5558\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.5450 - val_loss: 0.5480\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.5398 - val_loss: 0.5439\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5351 - val_loss: 0.5424\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5303 - val_loss: 0.5373\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.5265 - val_loss: 0.5353\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.5216 - val_loss: 0.5280\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.5186 - val_loss: 0.5271\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.5156 - val_loss: 0.5246\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.5127 - val_loss: 0.5225\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5087 - val_loss: 0.5165\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5156\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5040 - val_loss: 0.5120\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.5020 - val_loss: 0.5119\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4996 - val_loss: 0.5110\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4969 - val_loss: 0.5076\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4949 - val_loss: 0.5133\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4919 - val_loss: 0.5026\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4912 - val_loss: 0.5021\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4882 - val_loss: 0.5038\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4871 - val_loss: 0.4989\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4856 - val_loss: 0.5014\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4828 - val_loss: 0.4947\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4824 - val_loss: 0.4980\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4797 - val_loss: 0.4907\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.4803 - val_loss: 0.4922\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.4775 - val_loss: 0.4892\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.4768 - val_loss: 0.4935\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4750 - val_loss: 0.4879\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4736 - val_loss: 0.4955\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.4715 - val_loss: 0.4845\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4717 - val_loss: 0.4873\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4697 - val_loss: 0.4832\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4694 - val_loss: 0.4811\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4679 - val_loss: 0.4805\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.4672 - val_loss: 0.4799\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.4656 - val_loss: 0.4817\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4656 - val_loss: 0.4808\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4639 - val_loss: 0.4774\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4619 - val_loss: 0.4736\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4622 - val_loss: 0.4921\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4610 - val_loss: 0.4749\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4606 - val_loss: 0.4782\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4588 - val_loss: 0.4782\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4587 - val_loss: 0.4726\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4576 - val_loss: 0.4733\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4569 - val_loss: 0.4723\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4554 - val_loss: 0.4697\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.4545 - val_loss: 0.4729\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.4532 - val_loss: 0.4657\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4535 - val_loss: 0.4665\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.4527 - val_loss: 0.4659\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4509 - val_loss: 0.4716\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.4516 - val_loss: 0.4712\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4500 - val_loss: 0.4626\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.4496 - val_loss: 0.4621\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4484 - val_loss: 0.4615\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4479 - val_loss: 0.4628\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4472 - val_loss: 0.4642\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4463 - val_loss: 0.4602\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.4455 - val_loss: 0.4604\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4454 - val_loss: 0.4595\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4439 - val_loss: 0.4572\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4440 - val_loss: 0.4597\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4423 - val_loss: 0.4565\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.4430 - val_loss: 0.4600\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4415 - val_loss: 0.4555\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4411 - val_loss: 0.4545\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.4412 - val_loss: 0.4543\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4403 - val_loss: 0.4572\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4396 - val_loss: 0.4565\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.4386 - val_loss: 0.4530\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.4383 - val_loss: 0.4575\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4371 - val_loss: 0.4517\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.4372 - val_loss: 0.4529\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4364 - val_loss: 0.4514\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4354 - val_loss: 0.4494\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4351 - val_loss: 0.4495\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.4342 - val_loss: 0.4489\n",
      "121/121 [==============================] - 0s 541us/step - loss: 0.4285\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0602 - val_loss: 0.5425\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.5171 - val_loss: 0.4996\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.4878 - val_loss: 0.4820\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.4675 - val_loss: 0.4621\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4490 - val_loss: 0.4532\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.4378 - val_loss: 0.4372\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.4269 - val_loss: 0.4588\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4192 - val_loss: 0.4258\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4202\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4136\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4011 - val_loss: 0.4101\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3948 - val_loss: 0.4029\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3910 - val_loss: 0.4005\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4080\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3828 - val_loss: 0.3942\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3768 - val_loss: 0.3965\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3732 - val_loss: 0.3848\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3702 - val_loss: 0.3841\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3664 - val_loss: 0.3775\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3753\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3764\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.3714\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3543 - val_loss: 0.3707\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.3496 - val_loss: 0.3679\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.3487 - val_loss: 0.3626\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3445 - val_loss: 0.3591\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3421 - val_loss: 0.3574\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3409 - val_loss: 0.3549\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3389 - val_loss: 0.3554\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3360 - val_loss: 0.3726\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3342 - val_loss: 0.3496\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3316 - val_loss: 0.3493\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.3302 - val_loss: 0.3480\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3292 - val_loss: 0.3561\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3271 - val_loss: 0.3696\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3273 - val_loss: 0.3410\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3255 - val_loss: 0.3432\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3239 - val_loss: 0.3421\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3227 - val_loss: 0.3513\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3212 - val_loss: 0.3384\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3194 - val_loss: 0.3371\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3617\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3511\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.3180 - val_loss: 0.3585\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3177 - val_loss: 0.3965\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.3153 - val_loss: 0.3573\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3165 - val_loss: 0.3552\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3156 - val_loss: 0.3457\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3131 - val_loss: 0.3520\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3166 - val_loss: 0.3311\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3325\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.3298\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3109 - val_loss: 0.3309\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3116 - val_loss: 0.3295\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.3105 - val_loss: 0.3310\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3117 - val_loss: 0.3311\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3098 - val_loss: 0.3240\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3108 - val_loss: 0.3352\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3094 - val_loss: 0.3246\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3306\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.4082\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3258\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3730\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3066 - val_loss: 0.3368\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3067 - val_loss: 0.3227\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3060 - val_loss: 0.3210\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3058 - val_loss: 0.3292\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3044 - val_loss: 0.3292\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3043 - val_loss: 0.3254\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3040 - val_loss: 0.3318\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3024 - val_loss: 0.3242\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3017 - val_loss: 0.3237\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3286\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3185\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3029 - val_loss: 0.3305\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.3272\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3201\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.3273\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.2983 - val_loss: 0.3236\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3012 - val_loss: 0.3243\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3008 - val_loss: 0.3219\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.3181\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.3152\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3150\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.3243\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3199\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.2982 - val_loss: 0.3153\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2985 - val_loss: 0.3156\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.2973 - val_loss: 0.3230\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.2991 - val_loss: 0.3194\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.2965 - val_loss: 0.3433\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.2942 - val_loss: 0.3255\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.2971 - val_loss: 0.3221\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.2962 - val_loss: 0.3222\n",
      "121/121 [==============================] - 0s 597us/step - loss: 0.3322 0s - loss: 0.319\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6106 - val_loss: 0.6711\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.5795\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.5501 - val_loss: 0.5408\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.5158 - val_loss: 0.5116\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4901 - val_loss: 0.4891\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4708\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4500\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4348\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4201 - val_loss: 0.4289\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4084 - val_loss: 0.4135\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4017 - val_loss: 0.4159\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3948 - val_loss: 0.4016\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3894 - val_loss: 0.3962\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3836 - val_loss: 0.3942\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.4060\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3855\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3836\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3884\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3617 - val_loss: 0.3838\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3576 - val_loss: 0.3970\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3553 - val_loss: 0.3694\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3525 - val_loss: 0.3663\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3476 - val_loss: 0.3618\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3672\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3440 - val_loss: 0.3571\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3399 - val_loss: 0.3591\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3385 - val_loss: 0.3562\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3351 - val_loss: 0.3779\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3314 - val_loss: 0.3535\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3552\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3511\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3501\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3466\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.3451\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3190 - val_loss: 0.3518\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3440\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3385\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3543\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.3588\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3377\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3120 - val_loss: 0.3419\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3114 - val_loss: 0.3413\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3104 - val_loss: 0.3342\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3095 - val_loss: 0.3369\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3089 - val_loss: 0.3373\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3075 - val_loss: 0.3380\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3073 - val_loss: 0.3361\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3064 - val_loss: 0.3332\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3077 - val_loss: 0.3356\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3046 - val_loss: 0.3381\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3042 - val_loss: 0.3499\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3006 - val_loss: 0.3361\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3360\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3360\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.3308\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3308\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3282\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.3283\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3346\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3381\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.3321\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2977 - val_loss: 0.3266\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.3307\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3336\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.2965 - val_loss: 0.3315\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.2967 - val_loss: 0.3298\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.2947 - val_loss: 0.3302\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.2964 - val_loss: 0.3256\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.297 - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3371\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.2952 - val_loss: 0.3380\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.2946 - val_loss: 0.3302\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.2925 - val_loss: 0.3535\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.2940 - val_loss: 0.3242\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.2949 - val_loss: 0.3314\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.2918 - val_loss: 0.3390\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.2917 - val_loss: 0.3304\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.2909 - val_loss: 0.3264\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.2889 - val_loss: 0.3295\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.2909 - val_loss: 0.3240\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.2922 - val_loss: 0.3279\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2895 - val_loss: 0.3260\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.2928 - val_loss: 0.3292\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.2884 - val_loss: 0.3355\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.2891 - val_loss: 0.3287\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.2885 - val_loss: 0.3273\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.2897 - val_loss: 0.3372\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.2866 - val_loss: 0.3265\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.2869 - val_loss: 0.3299\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.2870 - val_loss: 0.3242\n",
      "121/121 [==============================] - 0s 496us/step - loss: 0.3139\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9596 - val_loss: 0.5479\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5144 - val_loss: 0.4803\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4778 - val_loss: 0.4818\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.4612 - val_loss: 0.4526\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4495 - val_loss: 0.4405\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.4436 - val_loss: 0.4395\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.4336 - val_loss: 0.4287\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4281 - val_loss: 0.4317\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.4208 - val_loss: 0.4217\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4155 - val_loss: 0.4218\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4139 - val_loss: 0.4144\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.4113\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.4118\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4064 - val_loss: 0.4076\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3954 - val_loss: 0.4112\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3935 - val_loss: 0.3975\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3900 - val_loss: 0.3977\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3895\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3946\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3834\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3893\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3683 - val_loss: 0.3794\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3810\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3606 - val_loss: 0.3901\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3716 - val_loss: 0.3701\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3701\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3558 - val_loss: 0.3763\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3648\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3684\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4798\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3493 - val_loss: 0.3537\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3423 - val_loss: 0.3610\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3583\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3595\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3566\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3507\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3504\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.3687\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3460\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3268 - val_loss: 0.3683\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3422\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.3432\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3372\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3372\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3473\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3502\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3708\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3233 - val_loss: 0.3366\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3151 - val_loss: 0.3429\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3183 - val_loss: 0.3492\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3192 - val_loss: 0.3298\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3288\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3161 - val_loss: 0.3543\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3120 - val_loss: 0.3355\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3340\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3346\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3095 - val_loss: 0.3270\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3286\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3307\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3359\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.3091 - val_loss: 0.3288\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3281\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3085 - val_loss: 0.3319\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3052 - val_loss: 0.3333\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3043 - val_loss: 0.3320\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3270\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3053 - val_loss: 0.3291\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3037 - val_loss: 0.3231\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3040 - val_loss: 0.3251\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3052 - val_loss: 0.3414\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3331\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3036 - val_loss: 0.3304\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.2990 - val_loss: 0.3293\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3452\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3383\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3016 - val_loss: 0.3239\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3352\n",
      "121/121 [==============================] - 0s 680us/step - loss: 0.3193\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9888 - val_loss: 3.9572\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0942 - val_loss: 2.5096\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0300 - val_loss: 1.6925\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4211 - val_loss: 1.2231\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 1.0679 - val_loss: 0.9515\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.8611 - val_loss: 0.7927\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.7391 - val_loss: 0.6997\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.6667 - val_loss: 0.6449\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.6231 - val_loss: 0.6124\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.5967 - val_loss: 0.5928\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.5803 - val_loss: 0.5809\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.5699 - val_loss: 0.5735\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.5632 - val_loss: 0.5687\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.5586 - val_loss: 0.5655\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5553 - val_loss: 0.5631\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.5528 - val_loss: 0.5612\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.5508 - val_loss: 0.5597\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5491 - val_loss: 0.5583\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.5477 - val_loss: 0.5571\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5463 - val_loss: 0.5559\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.5451 - val_loss: 0.5547\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.5439 - val_loss: 0.5537\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5428 - val_loss: 0.5526\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5417 - val_loss: 0.5515\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.5505\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.5398 - val_loss: 0.5496\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5388 - val_loss: 0.5486\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5379 - val_loss: 0.5478\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5371 - val_loss: 0.5469\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5362 - val_loss: 0.5460\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.5354 - val_loss: 0.5452\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5346 - val_loss: 0.5444\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.5339 - val_loss: 0.5436\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.5332 - val_loss: 0.5428\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5325 - val_loss: 0.5421\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.5318 - val_loss: 0.5415\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.5311 - val_loss: 0.5408\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.5305 - val_loss: 0.5402\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.5299 - val_loss: 0.5396\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.5293 - val_loss: 0.5390\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.5287 - val_loss: 0.5384\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.5282 - val_loss: 0.5378\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.5277 - val_loss: 0.5373\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5272 - val_loss: 0.5368\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.5267 - val_loss: 0.5362\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.5262 - val_loss: 0.5357\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.5257 - val_loss: 0.5352\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.5253 - val_loss: 0.5348\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.5249 - val_loss: 0.5343\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.5245 - val_loss: 0.5339\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5240 - val_loss: 0.5335\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5237 - val_loss: 0.5331\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.5233 - val_loss: 0.5327\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.5229 - val_loss: 0.5323\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5226 - val_loss: 0.5319\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.5222 - val_loss: 0.5315\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.5219 - val_loss: 0.5312\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.5216 - val_loss: 0.5309\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5213 - val_loss: 0.5306\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.5210 - val_loss: 0.5303\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.5207 - val_loss: 0.5299\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5205 - val_loss: 0.5297\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.5202 - val_loss: 0.5293\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.5199 - val_loss: 0.5291\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5197 - val_loss: 0.5288\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.5194 - val_loss: 0.5286\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.5192 - val_loss: 0.5284\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5282\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.5279\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5278\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5276\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5182 - val_loss: 0.5273\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.5271\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5178 - val_loss: 0.5269\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.5176 - val_loss: 0.5267\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.5265\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.5173 - val_loss: 0.5262\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5171 - val_loss: 0.5260\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.5169 - val_loss: 0.5259\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.5168 - val_loss: 0.5258\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5167 - val_loss: 0.5256\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.5165 - val_loss: 0.5254\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5164 - val_loss: 0.5252\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5163 - val_loss: 0.5251\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.5161 - val_loss: 0.5249\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5160 - val_loss: 0.5247\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5159 - val_loss: 0.5245\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.5243\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.5157 - val_loss: 0.5243\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5156 - val_loss: 0.5242\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.5155 - val_loss: 0.5240\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.5154 - val_loss: 0.5239\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5153 - val_loss: 0.5238\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.5152 - val_loss: 0.5237\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5151 - val_loss: 0.5237\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5150 - val_loss: 0.5236\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.5149 - val_loss: 0.5234\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.5148 - val_loss: 0.5233\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.5147 - val_loss: 0.5233\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.5147 - val_loss: 0.5232\n",
      "121/121 [==============================] - 0s 407us/step - loss: 0.6509\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 6.4248 - val_loss: 4.4626\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 3.4055 - val_loss: 2.5681\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 2.0533 - val_loss: 1.6594\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 1.3887 - val_loss: 1.1880\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 1.0357 - val_loss: 0.9300\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.8386 - val_loss: 0.7828\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.7251 - val_loss: 0.6973\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.6583 - val_loss: 0.6469\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.6185 - val_loss: 0.6166\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5942 - val_loss: 0.5980\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5791 - val_loss: 0.5863\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.5694 - val_loss: 0.5786\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.5630 - val_loss: 0.5735\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.5585 - val_loss: 0.5701\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5552 - val_loss: 0.5673\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.5527 - val_loss: 0.5651\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.5506 - val_loss: 0.5634\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.5489 - val_loss: 0.5620\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.5473 - val_loss: 0.5605\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.5459 - val_loss: 0.5594\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5446 - val_loss: 0.5580\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5434 - val_loss: 0.5569\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.5423 - val_loss: 0.5558\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.5413 - val_loss: 0.5550\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.5402 - val_loss: 0.5539\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.5393 - val_loss: 0.5533\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.5383 - val_loss: 0.5523\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5374 - val_loss: 0.5515\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5366 - val_loss: 0.5506\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5358 - val_loss: 0.5501\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.5350 - val_loss: 0.5493\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5343 - val_loss: 0.5489\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5335 - val_loss: 0.5481\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5328 - val_loss: 0.5477\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5470\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5466\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.5460\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 0.5453\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5444\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5440\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5434\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5433\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 0.5428\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5421\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5269 - val_loss: 0.5418\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5266 - val_loss: 0.5416\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5410\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5258 - val_loss: 0.5406\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 0.5405\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5405\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 0.5403\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 0.5397\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 0.5397\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5398\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 0.5394\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5394\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 0.5388\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 0.5383\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5385\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.5388\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.5379\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5217 - val_loss: 0.5373\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.5217 - val_loss: 0.5377\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.5214 - val_loss: 0.5371\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5213 - val_loss: 0.5372\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5368\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5370\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5207 - val_loss: 0.5370\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5206 - val_loss: 0.5366\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.5204 - val_loss: 0.5361\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.5202 - val_loss: 0.5358\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5201 - val_loss: 0.5361\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.5200 - val_loss: 0.5363\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.5198 - val_loss: 0.5359\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.5197 - val_loss: 0.5356\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5197 - val_loss: 0.5357\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.5194 - val_loss: 0.5352\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.5195 - val_loss: 0.5354\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.5193 - val_loss: 0.5359\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.5191 - val_loss: 0.5353\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5191 - val_loss: 0.5355\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.5190 - val_loss: 0.5354\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.5189 - val_loss: 0.5351\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.5187 - val_loss: 0.5346\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.5188 - val_loss: 0.5353\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5347\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5355\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5348\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5344\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.5184 - val_loss: 0.5344\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.5183 - val_loss: 0.5343\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5183 - val_loss: 0.5350\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.5184 - val_loss: 0.5349\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.5181 - val_loss: 0.5346\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.5181 - val_loss: 0.5347\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.5179 - val_loss: 0.5342\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5180 - val_loss: 0.5341\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5178 - val_loss: 0.5336\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.5179 - val_loss: 0.5344\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.5177 - val_loss: 0.5339\n",
      "121/121 [==============================] - 0s 523us/step - loss: 0.5352\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.7580 - val_loss: 4.0057\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 3.2615 - val_loss: 2.4517\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0542 - val_loss: 1.6411\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 1.4192 - val_loss: 1.1930\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 1.0674 - val_loss: 0.9383\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8666 - val_loss: 0.7913\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.7505 - val_loss: 0.7056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.6824 - val_loss: 0.6552\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.6419 - val_loss: 0.6248\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.6175 - val_loss: 0.6071\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.6025 - val_loss: 0.5961\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.5928 - val_loss: 0.5883\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5866 - val_loss: 0.5836\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.5823 - val_loss: 0.5804\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5789 - val_loss: 0.5775\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.5764 - val_loss: 0.5753\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5743 - val_loss: 0.5739\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5725 - val_loss: 0.5721\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.5708 - val_loss: 0.5704\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5694 - val_loss: 0.5692\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.5679 - val_loss: 0.5676\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.5667 - val_loss: 0.5670\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.5654 - val_loss: 0.5663\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5641 - val_loss: 0.5646\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.5630 - val_loss: 0.5644\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.5618 - val_loss: 0.5625\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.5608 - val_loss: 0.5612\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.5597 - val_loss: 0.5601\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.5588 - val_loss: 0.5603\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.5578 - val_loss: 0.5591\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.5569 - val_loss: 0.5581\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.5561 - val_loss: 0.5575\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5551 - val_loss: 0.5561\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5542 - val_loss: 0.5551\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.5536 - val_loss: 0.5546\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.5528 - val_loss: 0.5546\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.5520 - val_loss: 0.5548\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5514 - val_loss: 0.5543\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.5506 - val_loss: 0.5527\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5499 - val_loss: 0.5517\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.5493 - val_loss: 0.5522\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5487 - val_loss: 0.5519\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5481 - val_loss: 0.5507\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.5475 - val_loss: 0.5498\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5470 - val_loss: 0.5492\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5464 - val_loss: 0.5488\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.5459 - val_loss: 0.5478\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5455 - val_loss: 0.5478\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.5449 - val_loss: 0.5478\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.5445 - val_loss: 0.5476\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5440 - val_loss: 0.5472\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5435 - val_loss: 0.5461\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.5431 - val_loss: 0.5451\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5428 - val_loss: 0.5451\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.5423 - val_loss: 0.5462\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.5420 - val_loss: 0.5459\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5416 - val_loss: 0.5450\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.5413 - val_loss: 0.5447\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.5409 - val_loss: 0.5439\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5406 - val_loss: 0.5441\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.5401 - val_loss: 0.5427\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.5400 - val_loss: 0.5433\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.5397 - val_loss: 0.5433\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5394 - val_loss: 0.5427\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.5391 - val_loss: 0.5434\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.5387 - val_loss: 0.5420\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.5386 - val_loss: 0.5421\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5382 - val_loss: 0.5413\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5379 - val_loss: 0.5403\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.5377 - val_loss: 0.5398\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.5377 - val_loss: 0.5401\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5373 - val_loss: 0.5409\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5372 - val_loss: 0.5411\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5370 - val_loss: 0.5406\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5367 - val_loss: 0.5399\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5365 - val_loss: 0.5405\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.5363 - val_loss: 0.5396\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5362 - val_loss: 0.5399\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 0.5394\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5389\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5357 - val_loss: 0.5388\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5355 - val_loss: 0.5400\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5395\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5399\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5351 - val_loss: 0.5395\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5398\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5348 - val_loss: 0.5399\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.5347 - val_loss: 0.5399\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.5346 - val_loss: 0.5394\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.5344 - val_loss: 0.5389\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.5342 - val_loss: 0.5381\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.5341 - val_loss: 0.5377\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.5341 - val_loss: 0.5379\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.5340 - val_loss: 0.5378\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.5338 - val_loss: 0.5375\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 704us/step - loss: 0.5337 - val_loss: 0.5376\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.5336 - val_loss: 0.5386\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5335 - val_loss: 0.5393\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5331 - val_loss: 0.5372\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.5333 - val_loss: 0.5365\n",
      "121/121 [==============================] - 0s 435us/step - loss: 0.5063\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 5.0141 - val_loss: 4.3221\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 3.7704 - val_loss: 3.2699\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 2.8914 - val_loss: 2.5277\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 2.2693 - val_loss: 2.0035\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 1.8281 - val_loss: 1.6327\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 1.5143 - val_loss: 1.3700\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 1.2905 - val_loss: 1.1837\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 1.1305 - val_loss: 1.0512\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 1.0154 - val_loss: 0.9568\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.9324 - val_loss: 0.8893\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.8721 - val_loss: 0.8408\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 673us/step - loss: 0.8278 - val_loss: 0.8056\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.7951 - val_loss: 0.7799\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.7704 - val_loss: 0.7609\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.7516 - val_loss: 0.7465\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7369 - val_loss: 0.7355\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.7253 - val_loss: 0.7268\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.7158 - val_loss: 0.7198\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.7079 - val_loss: 0.7139\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7012 - val_loss: 0.7089\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.6953 - val_loss: 0.7044\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6900 - val_loss: 0.7003\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.6851 - val_loss: 0.6965\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.6807 - val_loss: 0.6928\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.6765 - val_loss: 0.6894\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.6726 - val_loss: 0.6861\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.6688 - val_loss: 0.6827\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6652 - val_loss: 0.6795\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6617 - val_loss: 0.6764\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.6584 - val_loss: 0.6733\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.6551 - val_loss: 0.6704\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.6519 - val_loss: 0.6675\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.6488 - val_loss: 0.6645\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.6458 - val_loss: 0.6617\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.6429 - val_loss: 0.6588\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.6400 - val_loss: 0.6561\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.6373 - val_loss: 0.6534\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.6345 - val_loss: 0.6507\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.6319 - val_loss: 0.6481\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.6293 - val_loss: 0.6455\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.6267 - val_loss: 0.6430\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.6243 - val_loss: 0.6405\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.6218 - val_loss: 0.6381\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.6195 - val_loss: 0.6357\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.6172 - val_loss: 0.6334\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6149 - val_loss: 0.6311\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.6127 - val_loss: 0.6289\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.6105 - val_loss: 0.6267\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.6084 - val_loss: 0.6246\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.6064 - val_loss: 0.6224\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.6044 - val_loss: 0.6204\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.6024 - val_loss: 0.6183\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.6005 - val_loss: 0.6163\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.5986 - val_loss: 0.6144\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.5967 - val_loss: 0.6125\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5949 - val_loss: 0.6106\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5932 - val_loss: 0.6088\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5914 - val_loss: 0.6070\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.5898 - val_loss: 0.6052\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5881 - val_loss: 0.6035\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.5865 - val_loss: 0.6018\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5849 - val_loss: 0.6002\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5834 - val_loss: 0.5986\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5819 - val_loss: 0.5970\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.5804 - val_loss: 0.5955\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.5790 - val_loss: 0.5940\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5776 - val_loss: 0.5925\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5762 - val_loss: 0.5911\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5749 - val_loss: 0.5897\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.5883\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5723 - val_loss: 0.5870\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.5856\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5698 - val_loss: 0.5844\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5686 - val_loss: 0.5831\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5674 - val_loss: 0.5819\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5663 - val_loss: 0.5807\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5651 - val_loss: 0.5794\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5640 - val_loss: 0.5784\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5630 - val_loss: 0.5772\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5619 - val_loss: 0.5761\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5609 - val_loss: 0.5750\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5599 - val_loss: 0.5739\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5589 - val_loss: 0.5729\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5579 - val_loss: 0.5719\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.5570 - val_loss: 0.5709\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5561 - val_loss: 0.5699\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.5552 - val_loss: 0.5689\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5543 - val_loss: 0.5680\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5534 - val_loss: 0.5671\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.5526 - val_loss: 0.5662\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5517 - val_loss: 0.5653\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5509 - val_loss: 0.5644\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5501 - val_loss: 0.5636\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.5494 - val_loss: 0.5628\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5486 - val_loss: 0.5619\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5479 - val_loss: 0.5611\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5471 - val_loss: 0.5604\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.5464 - val_loss: 0.5596\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5457 - val_loss: 0.5589\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5451 - val_loss: 0.5582\n",
      "121/121 [==============================] - 0s 553us/step - loss: 0.5745\n",
      "Epoch 1/100\n",
      "232/242 [===========================>..] - ETA: 0s - loss: 5.9604WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.8844 - val_loss: 4.9239\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 4.1403 - val_loss: 3.5200\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 3.0020 - val_loss: 2.5905\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 2.2412 - val_loss: 1.9655\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 1.7266 - val_loss: 1.5388\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 1.3739 - val_loss: 1.2454\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 1.1299 - val_loss: 1.0419\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.9600 - val_loss: 0.9003\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.8411 - val_loss: 0.8011\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.7574 - val_loss: 0.7315\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.6983 - val_loss: 0.6823\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.6562 - val_loss: 0.6474\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.6262 - val_loss: 0.6227\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.6048 - val_loss: 0.6051\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5893 - val_loss: 0.5925\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5781 - val_loss: 0.5834\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.5698 - val_loss: 0.5767\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5636 - val_loss: 0.5717\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.5590 - val_loss: 0.5679\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5554 - val_loss: 0.5651\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5526 - val_loss: 0.5629\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5504 - val_loss: 0.5611\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5486 - val_loss: 0.5597\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5471 - val_loss: 0.5584\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.5458 - val_loss: 0.5574\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5446 - val_loss: 0.5565\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.5436 - val_loss: 0.5556\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5426 - val_loss: 0.5548\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5418 - val_loss: 0.5541\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5410 - val_loss: 0.5534\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5402 - val_loss: 0.5527\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5395 - val_loss: 0.5521\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.5388 - val_loss: 0.5515\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5381 - val_loss: 0.5509\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.5375 - val_loss: 0.5503\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.5369 - val_loss: 0.5499\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5363 - val_loss: 0.5493\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5357 - val_loss: 0.5488\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5352 - val_loss: 0.5483\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5346 - val_loss: 0.5478\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5341 - val_loss: 0.5473\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.5336 - val_loss: 0.5469\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.5331 - val_loss: 0.5465\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.5326 - val_loss: 0.5462\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.5322 - val_loss: 0.5457\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.5317 - val_loss: 0.5453\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.5313 - val_loss: 0.5450\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5308 - val_loss: 0.5446\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.5304 - val_loss: 0.5443\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.5300 - val_loss: 0.5440\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.5296 - val_loss: 0.5437\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.5293 - val_loss: 0.5432\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.5289 - val_loss: 0.5429\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.5286 - val_loss: 0.5426\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.5282 - val_loss: 0.5422\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5419\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5275 - val_loss: 0.5416\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5272 - val_loss: 0.5413\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5269 - val_loss: 0.5411\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.5266 - val_loss: 0.5410\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.5263 - val_loss: 0.5407\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.5260 - val_loss: 0.5404\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5258 - val_loss: 0.5401\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5255 - val_loss: 0.5400\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5252 - val_loss: 0.5399\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.5250 - val_loss: 0.5396\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.5247 - val_loss: 0.5394\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5245 - val_loss: 0.5391\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.5243 - val_loss: 0.5390\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 704us/step - loss: 0.5240 - val_loss: 0.5387\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.5238 - val_loss: 0.5386\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.5236 - val_loss: 0.5383\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.5234 - val_loss: 0.5383\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.5232 - val_loss: 0.5382\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.5230 - val_loss: 0.5381\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5379\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5226 - val_loss: 0.5377\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5224 - val_loss: 0.5374\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.5223 - val_loss: 0.5374\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5221 - val_loss: 0.5371\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5219 - val_loss: 0.5371\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5218 - val_loss: 0.5368\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 0.5368\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.5215 - val_loss: 0.5367\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5364\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.5212 - val_loss: 0.5364\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.5211 - val_loss: 0.5365\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5209 - val_loss: 0.5362\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.5208 - val_loss: 0.5361\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5361\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5358\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5356\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 0.5354\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 0.5353\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5201 - val_loss: 0.5355\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.5354\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.5355\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5197 - val_loss: 0.5353\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5197 - val_loss: 0.5352\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5196 - val_loss: 0.5352\n",
      "121/121 [==============================] - 0s 577us/step - loss: 0.5399\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.4699 - val_loss: 4.0173\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 3.9390 - val_loss: 2.9983\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 2.9153 - val_loss: 2.2955\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 2.2196 - val_loss: 1.8024\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 1.7435 - val_loss: 1.4583\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 1.4141 - val_loss: 1.2158\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1838 - val_loss: 1.0441\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0222 - val_loss: 0.9228\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9079 - val_loss: 0.8365\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8270 - val_loss: 0.7761\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7694 - val_loss: 0.7329\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.7275 - val_loss: 0.7017\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6974 - val_loss: 0.6797\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6755 - val_loss: 0.6639\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6592 - val_loss: 0.6520\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6473 - val_loss: 0.6434\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6381 - val_loss: 0.6368\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6311 - val_loss: 0.6330\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6256 - val_loss: 0.6294\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6212 - val_loss: 0.6264\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6176 - val_loss: 0.6238\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6222\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6205\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6099 - val_loss: 0.6184\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.6079 - val_loss: 0.6164\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.6061 - val_loss: 0.6159\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.6045 - val_loss: 0.6146\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.6029 - val_loss: 0.6126\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6015 - val_loss: 0.6116\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6001 - val_loss: 0.6107\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6094\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6084\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.6076\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5951 - val_loss: 0.6064\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5939 - val_loss: 0.6055\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5929 - val_loss: 0.6048\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5916 - val_loss: 0.6035\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5905 - val_loss: 0.6025\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5895 - val_loss: 0.6011\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5883 - val_loss: 0.6000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5873 - val_loss: 0.5984\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.5863 - val_loss: 0.5976\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5853 - val_loss: 0.5958\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5844 - val_loss: 0.5949\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.5834 - val_loss: 0.5936\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.5825 - val_loss: 0.5933\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.5816 - val_loss: 0.5921\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5807 - val_loss: 0.5907\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.5904\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5789 - val_loss: 0.5890\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5781 - val_loss: 0.5885\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - val_loss: 0.5880\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - val_loss: 0.5878\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5757 - val_loss: 0.5863\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 0.5854\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5742 - val_loss: 0.5849\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.5843\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.5830\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - val_loss: 0.5823\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5712 - val_loss: 0.5812\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5705 - val_loss: 0.5802\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5698 - val_loss: 0.5796\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.5692 - val_loss: 0.5789\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5684 - val_loss: 0.5775\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.5678 - val_loss: 0.5777\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.5671 - val_loss: 0.5765\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.5665 - val_loss: 0.5754\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5660 - val_loss: 0.5750\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.5653 - val_loss: 0.5741\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.5644 - val_loss: 0.5735\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.5642 - val_loss: 0.5729\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.5637 - val_loss: 0.5730\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5631 - val_loss: 0.5726\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.5624 - val_loss: 0.5716\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5618 - val_loss: 0.5704\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.5614 - val_loss: 0.5702\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.5608 - val_loss: 0.5694\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.5603 - val_loss: 0.5681\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.5599 - val_loss: 0.5681\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5594 - val_loss: 0.5683\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.5589 - val_loss: 0.5678\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5584 - val_loss: 0.5676\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.5579 - val_loss: 0.5683\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.5574 - val_loss: 0.5675\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.5570 - val_loss: 0.5673\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.5565 - val_loss: 0.5668\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5560 - val_loss: 0.5651\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5557 - val_loss: 0.5645\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.5552 - val_loss: 0.5638\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.5548 - val_loss: 0.5634\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5544 - val_loss: 0.5629\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5541 - val_loss: 0.5628\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.5536 - val_loss: 0.5621\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.5532 - val_loss: 0.5624\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5528 - val_loss: 0.5613\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.5525 - val_loss: 0.5611\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.5521 - val_loss: 0.5610\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.5517 - val_loss: 0.5601\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5515 - val_loss: 0.5601\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.5510 - val_loss: 0.5599\n",
      "121/121 [==============================] - 0s 527us/step - loss: 0.5206\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001CB5789EF88>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-29d260ab60ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mrnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m rnd.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n\u001b[1;32m---> 12\u001b[1;33m        callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001CB5789EF88>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params_dict = {\n",
    "    \"n_hidden\" : [0, 1, 2, 3] ,\n",
    "    \"n_neurons\" : np.arange(1,100) ,\n",
    "    \"learning_rate\" : reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd = RandomizedSearchCV(keras_reg, params_dict, n_iter=10, cv=3)\n",
    "rnd.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "       callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.007210755428272255, 'n_hidden': 3, 'n_neurons': 16}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32181602716445923"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
